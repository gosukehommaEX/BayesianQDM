---
title: "Bayesian Decision Making for Continuous Endpoints"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Bayesian Decision Making for Continuous Endpoints}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 7,
  fig.height = 5,
  fig.alt = "Visualization of statistical methods and decision probabilities for continuous endpoints"
)
```

```{r setup}
library(BayesianQDM)
library(dplyr)
library(tidyr)
library(ggplot2)
library(purrr)
```

## Introduction

This vignette demonstrates Bayesian decision-making for continuous endpoints using the BayesianQDM package. Continuous endpoints (e.g., change in biomarker levels, symptom scores, or quality of life measures) are common in clinical trials and require different statistical approaches than binary endpoints.

## Theoretical Background

### Statistical Framework

For continuous endpoints, we assume:
- Outcomes follow normal distributions with unknown means and variances
- Prior distributions on parameters (Normal-Inverse-Chi-squared or vague priors)
- Posterior distributions follow t-distributions

### Calculation Methods

The package provides four computational approaches:

1. **NI (Numerical Integration)**: Exact calculation using convolution
2. **WS (Welch-Satterthwaite)**: Fast approximation for unequal variances  
3. **MC (Monte Carlo)**: Simulation-based approach (not used in this vignette for speed)
4. **MCMC (Markov Chain Monte Carlo)**: Sampling-based approach for external data incorporation

For this vignette, we focus on the fastest methods (NI and WS) to ensure reasonable build times.

## Basic Posterior Probability Calculation

### Standard Controlled Design

Let's start with a basic two-arm trial:

```{r basic-example}
# Calculate posterior probability that treatment effect > 1.5
posterior_prob <- BayesPostPredContinuous(
  prob = 'posterior',
  design = 'controlled', 
  prior = 'vague',
  CalcMethod = 'WS',  # Fast method for vignette
  theta0 = 1.5,
  n1 = 12, n2 = 12,
  bar.y1 = 5.2, bar.y2 = 3.1,
  s1 = 1.8, s2 = 1.6
)

cat("Posterior probability P(μ₁ - μ₂ > 1.5):", round(posterior_prob, 4))
```

### Comparison of Calculation Methods

Let's compare the accuracy and speed of different methods:

```{r method-comparison}
# Set common parameters
params <- list(
  prob = 'posterior',
  design = 'controlled',
  prior = 'vague', 
  theta0 = 1,
  n1 = 15, n2 = 15,
  bar.y1 = 4.2, bar.y2 = 2.8,
  s1 = 1.5, s2 = 1.4
)

# Compare NI and WS methods (skip MC and MCMC for vignette speed)
ni_result <- do.call(BayesPostPredContinuous, c(params, list(CalcMethod = 'NI')))
ws_result <- do.call(BayesPostPredContinuous, c(params, list(CalcMethod = 'WS')))

# Results comparison
results_df <- data.frame(
  Method = c("Numerical Integration", "Welch-Satterthwaite"),
  Probability = c(ni_result, ws_result),
  Speed = c("Slower", "Faster"),
  Accuracy = c("Exact", "Approximation")
)

knitr::kable(results_df, digits = 4, caption = "Method Comparison")
```

## Go/NoGo/Gray Decision Framework

### Basic Decision Probabilities

```{r decision-framework}
# Calculate Go/NoGo/Gray probabilities
decision_result <- BayesDecisionProbContinuous(
  nsim = 30,  # Reduced for vignette speed
  prob = 'posterior',
  design = 'controlled',
  prior = 'vague',
  CalcMethod = 'WS',  # Fast method
  theta.TV = 2.0,   # Target value for Go
  theta.MAV = 0.5,  # Minimum acceptable value for NoGo
  theta.NULL = NULL,
  gamma1 = 0.8,     # Go threshold
  gamma2 = 0.3,     # NoGo threshold
  n1 = 12, n2 = 12,
  mu1 = 4.5, mu2 = 2.0,
  sigma1 = 1.5, sigma2 = 1.3,
  seed = 123
)

print(decision_result)
```

### Visualizing Decision Probabilities

```{r decision-visualization}
# Create operating characteristics
scenarios <- expand.grid(
  true_diff = c(0, 0.5, 1.0, 1.5, 2.0, 2.5),
  sample_size = c(10, 15, 20)
) %>%
  rowwise() %>%
  mutate(
    decision = list(BayesDecisionProbContinuous(
      nsim = 20,  # Reduced for vignette speed
      prob = 'posterior',
      design = 'controlled',
      prior = 'vague',
      CalcMethod = 'WS',
      theta.TV = 1.5,
      theta.MAV = 0.5,
      theta.NULL = NULL,
      gamma1 = 0.8,
      gamma2 = 0.3,
      n1 = sample_size, n2 = sample_size,
      mu1 = 2.0 + true_diff, mu2 = 2.0,
      sigma1 = 1.5, sigma2 = 1.5,
      seed = 123
    ))
  ) %>%
  unnest_wider(decision)

# Plot operating characteristics  
scenarios_long <- scenarios %>%
  select(true_diff, sample_size, Go, NoGo, Gray) %>%
  pivot_longer(cols = c(Go, NoGo, Gray), names_to = "Decision", values_to = "Probability")

ggplot(scenarios_long, aes(x = true_diff, y = Probability, color = Decision)) +
  geom_line(linewidth = 1) +
  geom_point(size = 2) +
  facet_wrap(~paste("N =", sample_size, "per arm")) +
  scale_color_manual(values = c('Go' = '#2E8B57', 'Gray' = '#808080', 'NoGo' = '#DC143C')) +
  labs(
    title = "Operating Characteristics for Continuous Endpoints",
    x = "True Treatment Difference",
    y = "Decision Probability",
    caption = "Note: Reduced simulation size for vignette speed"
  ) +
  theme_bw()
```

## Advanced Prior Specifications

### Normal-Inverse-Chi-squared Priors

For incorporating prior knowledge:

```{r informative-priors}
# Example with informative priors
informative_result <- BayesPostPredContinuous(
  prob = 'posterior',
  design = 'controlled',
  prior = 'N-Inv-Chisq',
  CalcMethod = 'NI',
  theta0 = 1.0,
  n1 = 10, n2 = 10,
  bar.y1 = 3.2, bar.y2 = 2.1,
  s1 = 1.4, s2 = 1.2,
  # Prior parameters
  kappa01 = 2, kappa02 = 2,
  nu01 = 4, nu02 = 4, 
  mu01 = 3.0, mu02 = 2.0,
  sigma01 = 1.5, sigma02 = 1.5
)

cat("Posterior probability with informative priors:", round(informative_result, 4))
```

## External Data Incorporation

### Power Prior with MCMC

When external/historical data is available, we can use power priors with MCMC sampling:

```{r external-data, eval=FALSE}
# Note: This example is not evaluated in the vignette due to computation time
# In practice, use higher nMCMCsample values (e.g., 10000)

external_result <- pMCMCdiff(
  nMCMCsample = 1000,  # Reduced for demonstration
  q = 1.5,
  mu.n1 = 4.2, mu.n2 = 2.8,
  sd.n1 = 1.5, sd.n2 = 1.4, 
  n1 = 12, n2 = 12,
  ne1 = 24, ne2 = 24,  # External data sample sizes
  alpha01 = 0.5, alpha02 = 0.5  # Power prior parameters
)

cat("Probability with external data:", round(external_result, 4))
```

The power prior parameters (α₀₁, α₀₂) control the degree of borrowing:
- α = 0: No borrowing (ignore external data)
- α = 1: Full borrowing (external data weighted equally)
- 0 < α < 1: Partial borrowing

## Practical Considerations

### Sample Size Planning

```{r sample-size-planning}
# Evaluate required sample size for desired operating characteristics
sample_sizes <- seq(5, 25, by = 5)

oc_results <- do.call(rbind, lapply(sample_sizes, function(.x) {
  result <- BayesDecisionProbContinuous(
    nsim = 20,  # Reduced for vignette
    prob = 'posterior',
    design = 'controlled', 
    prior = 'vague',
    CalcMethod = 'WS',
    theta.TV = 1.5, theta.MAV = 0.5, theta.NULL = NULL,
    gamma1 = 0.8, gamma2 = 0.3,
    n1 = .x, n2 = .x,
    mu1 = 3.5, mu2 = 2.0,  # Assume true effect of 1.5
    sigma1 = 1.5, sigma2 = 1.5,
    seed = 123
  )
  
  data.frame(
    sample_size = .x,
    go_prob = result$Go,
    nogo_prob = result$NoGo,
    gray_prob = result$Gray
  )
}))

ggplot(oc_results, aes(x = sample_size)) +
  geom_line(aes(y = go_prob, color = "Go"), linewidth = 1) +
  geom_line(aes(y = gray_prob, color = "Gray"), linewidth = 1) +
  geom_line(aes(y = nogo_prob, color = "NoGo"), linewidth = 1) +
  scale_color_manual(values = c('Go' = '#2E8B57', 'Gray' = '#808080', 'NoGo' = '#DC143C')) +
  labs(
    title = "Power Analysis: Sample Size vs Decision Probabilities",
    x = "Sample Size (per arm)",
    y = "Decision Probability",
    color = "Decision",
    subtitle = "Assuming true treatment effect = 1.5"
  ) +
  theme_bw()
```

### Method Selection Guidelines

Choose calculation methods based on your needs:

- **NI**: Use when exact results are required and computational time is not critical
- **WS**: Use for quick approximations, especially with unequal variances
- **MC**: Use when other methods fail or for sensitivity analysis (not shown in vignette)
- **MCMC**: Use when incorporating external data with power priors

## Summary

This vignette demonstrated:

1. **Basic probability calculations** for continuous endpoints
2. **Go/NoGo/Gray decision framework** with customizable thresholds  
3. **Method comparisons** balancing accuracy and speed
4. **Prior specification** for incorporating prior knowledge
5. **External data incorporation** using power priors and MCMC
6. **Operating characteristics** for trial planning

The BayesianQDM package provides flexible tools for evidence-based decision making in clinical trials with continuous endpoints. For computational efficiency in routine use, consider the WS method for most applications, reserving exact methods (NI) and simulation approaches (MCMC) for critical decisions or when external data is available.

## References

For more details on the statistical methods, see:

- The main BayesianQDM vignette for framework overview
- Function documentation for parameter specifications  
- The binary endpoints vignette for comparison with discrete outcomes
